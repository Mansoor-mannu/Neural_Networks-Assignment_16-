{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "471cb380",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76d3b4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.70</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>114.71</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>111.61</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>111.78</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>110.19</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>110.74</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>111.58</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  114.70  10.605   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  114.72  10.598   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  114.71  10.601   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  114.72  10.606   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  114.72  10.612   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  111.61  10.400   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  111.78  10.433   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  110.19  10.483   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  110.74  10.533   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  111.58  10.583   \n",
       "\n",
       "           CO     NOX  \n",
       "0      3.1547  82.722  \n",
       "1      3.2363  82.776  \n",
       "2      3.2012  82.468  \n",
       "3      3.1923  82.670  \n",
       "4      3.2484  82.311  \n",
       "...       ...     ...  \n",
       "15034  4.5186  79.559  \n",
       "15035  4.8470  79.917  \n",
       "15036  7.9632  90.912  \n",
       "15037  6.2494  93.227  \n",
       "15038  4.9816  92.498  \n",
       "\n",
       "[15039 rows x 11 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "gas = pd.read_csv(\"D:\\\\DATA SCIENCE\\\\ASSIGNMENTS\\\\Neural Networks\\\\gas_turbines.csv\")\n",
    "gas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2be9395c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15039 entries, 0 to 15038\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   AT      15039 non-null  float64\n",
      " 1   AP      15039 non-null  float64\n",
      " 2   AH      15039 non-null  float64\n",
      " 3   AFDP    15039 non-null  float64\n",
      " 4   GTEP    15039 non-null  float64\n",
      " 5   TIT     15039 non-null  float64\n",
      " 6   TAT     15039 non-null  float64\n",
      " 7   TEY     15039 non-null  float64\n",
      " 8   CDP     15039 non-null  float64\n",
      " 9   CO      15039 non-null  float64\n",
      " 10  NOX     15039 non-null  float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "gas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab15db76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AT</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.412953</td>\n",
       "      <td>-0.549432</td>\n",
       "      <td>-0.099333</td>\n",
       "      <td>-0.049103</td>\n",
       "      <td>0.093067</td>\n",
       "      <td>0.338569</td>\n",
       "      <td>-0.207495</td>\n",
       "      <td>-0.100705</td>\n",
       "      <td>-0.088588</td>\n",
       "      <td>-0.600006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP</th>\n",
       "      <td>-0.412953</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042573</td>\n",
       "      <td>0.040318</td>\n",
       "      <td>0.078575</td>\n",
       "      <td>0.029650</td>\n",
       "      <td>-0.223479</td>\n",
       "      <td>0.146939</td>\n",
       "      <td>0.131198</td>\n",
       "      <td>0.041614</td>\n",
       "      <td>0.256744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AH</th>\n",
       "      <td>-0.549432</td>\n",
       "      <td>0.042573</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.119249</td>\n",
       "      <td>-0.202784</td>\n",
       "      <td>-0.247781</td>\n",
       "      <td>0.010859</td>\n",
       "      <td>-0.110272</td>\n",
       "      <td>-0.182010</td>\n",
       "      <td>0.165505</td>\n",
       "      <td>0.143061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFDP</th>\n",
       "      <td>-0.099333</td>\n",
       "      <td>0.040318</td>\n",
       "      <td>-0.119249</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.744251</td>\n",
       "      <td>0.627254</td>\n",
       "      <td>-0.571541</td>\n",
       "      <td>0.717995</td>\n",
       "      <td>0.727152</td>\n",
       "      <td>-0.334207</td>\n",
       "      <td>-0.037299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTEP</th>\n",
       "      <td>-0.049103</td>\n",
       "      <td>0.078575</td>\n",
       "      <td>-0.202784</td>\n",
       "      <td>0.744251</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.874526</td>\n",
       "      <td>-0.756884</td>\n",
       "      <td>0.977042</td>\n",
       "      <td>0.993784</td>\n",
       "      <td>-0.508259</td>\n",
       "      <td>-0.208496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIT</th>\n",
       "      <td>0.093067</td>\n",
       "      <td>0.029650</td>\n",
       "      <td>-0.247781</td>\n",
       "      <td>0.627254</td>\n",
       "      <td>0.874526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.357320</td>\n",
       "      <td>0.891587</td>\n",
       "      <td>0.887238</td>\n",
       "      <td>-0.688272</td>\n",
       "      <td>-0.231636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAT</th>\n",
       "      <td>0.338569</td>\n",
       "      <td>-0.223479</td>\n",
       "      <td>0.010859</td>\n",
       "      <td>-0.571541</td>\n",
       "      <td>-0.756884</td>\n",
       "      <td>-0.357320</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.720356</td>\n",
       "      <td>-0.744740</td>\n",
       "      <td>0.063404</td>\n",
       "      <td>0.009888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEY</th>\n",
       "      <td>-0.207495</td>\n",
       "      <td>0.146939</td>\n",
       "      <td>-0.110272</td>\n",
       "      <td>0.717995</td>\n",
       "      <td>0.977042</td>\n",
       "      <td>0.891587</td>\n",
       "      <td>-0.720356</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988473</td>\n",
       "      <td>-0.541751</td>\n",
       "      <td>-0.102631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDP</th>\n",
       "      <td>-0.100705</td>\n",
       "      <td>0.131198</td>\n",
       "      <td>-0.182010</td>\n",
       "      <td>0.727152</td>\n",
       "      <td>0.993784</td>\n",
       "      <td>0.887238</td>\n",
       "      <td>-0.744740</td>\n",
       "      <td>0.988473</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.520783</td>\n",
       "      <td>-0.169103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO</th>\n",
       "      <td>-0.088588</td>\n",
       "      <td>0.041614</td>\n",
       "      <td>0.165505</td>\n",
       "      <td>-0.334207</td>\n",
       "      <td>-0.508259</td>\n",
       "      <td>-0.688272</td>\n",
       "      <td>0.063404</td>\n",
       "      <td>-0.541751</td>\n",
       "      <td>-0.520783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.316743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>-0.600006</td>\n",
       "      <td>0.256744</td>\n",
       "      <td>0.143061</td>\n",
       "      <td>-0.037299</td>\n",
       "      <td>-0.208496</td>\n",
       "      <td>-0.231636</td>\n",
       "      <td>0.009888</td>\n",
       "      <td>-0.102631</td>\n",
       "      <td>-0.169103</td>\n",
       "      <td>0.316743</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AT        AP        AH      AFDP      GTEP       TIT       TAT  \\\n",
       "AT    1.000000 -0.412953 -0.549432 -0.099333 -0.049103  0.093067  0.338569   \n",
       "AP   -0.412953  1.000000  0.042573  0.040318  0.078575  0.029650 -0.223479   \n",
       "AH   -0.549432  0.042573  1.000000 -0.119249 -0.202784 -0.247781  0.010859   \n",
       "AFDP -0.099333  0.040318 -0.119249  1.000000  0.744251  0.627254 -0.571541   \n",
       "GTEP -0.049103  0.078575 -0.202784  0.744251  1.000000  0.874526 -0.756884   \n",
       "TIT   0.093067  0.029650 -0.247781  0.627254  0.874526  1.000000 -0.357320   \n",
       "TAT   0.338569 -0.223479  0.010859 -0.571541 -0.756884 -0.357320  1.000000   \n",
       "TEY  -0.207495  0.146939 -0.110272  0.717995  0.977042  0.891587 -0.720356   \n",
       "CDP  -0.100705  0.131198 -0.182010  0.727152  0.993784  0.887238 -0.744740   \n",
       "CO   -0.088588  0.041614  0.165505 -0.334207 -0.508259 -0.688272  0.063404   \n",
       "NOX  -0.600006  0.256744  0.143061 -0.037299 -0.208496 -0.231636  0.009888   \n",
       "\n",
       "           TEY       CDP        CO       NOX  \n",
       "AT   -0.207495 -0.100705 -0.088588 -0.600006  \n",
       "AP    0.146939  0.131198  0.041614  0.256744  \n",
       "AH   -0.110272 -0.182010  0.165505  0.143061  \n",
       "AFDP  0.717995  0.727152 -0.334207 -0.037299  \n",
       "GTEP  0.977042  0.993784 -0.508259 -0.208496  \n",
       "TIT   0.891587  0.887238 -0.688272 -0.231636  \n",
       "TAT  -0.720356 -0.744740  0.063404  0.009888  \n",
       "TEY   1.000000  0.988473 -0.541751 -0.102631  \n",
       "CDP   0.988473  1.000000 -0.520783 -0.169103  \n",
       "CO   -0.541751 -0.520783  1.000000  0.316743  \n",
       "NOX  -0.102631 -0.169103  0.316743  1.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gas.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "133bba8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 11)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count of duplicated rows\n",
    "gas[gas.duplicated()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42aeb3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550.01    270\n",
       "550.00    268\n",
       "550.04    266\n",
       "550.03    253\n",
       "549.98    252\n",
       "         ... \n",
       "536.25      1\n",
       "539.04      1\n",
       "534.51      1\n",
       "529.28      1\n",
       "525.37      1\n",
       "Name: TAT, Length: 2340, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gas['TAT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29a54596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating VIF for multicolinearity\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def calc_vif(X):\n",
    "\n",
    "    # Calculating VIF\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variables\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "    return(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01c60c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variables</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT</td>\n",
       "      <td>3.414439e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AP</td>\n",
       "      <td>1.842147e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AH</td>\n",
       "      <td>6.863745e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFDP</td>\n",
       "      <td>8.580114e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GTEP</td>\n",
       "      <td>1.233878e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TIT</td>\n",
       "      <td>1.372092e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TAT</td>\n",
       "      <td>8.166382e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CDP</td>\n",
       "      <td>3.858125e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CO</td>\n",
       "      <td>3.813210e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NOX</td>\n",
       "      <td>1.071006e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  variables           VIF\n",
       "0        AT  3.414439e+01\n",
       "1        AP  1.842147e+04\n",
       "2        AH  6.863745e+01\n",
       "3      AFDP  8.580114e+01\n",
       "4      GTEP  1.233878e+04\n",
       "5       TIT  1.372092e+06\n",
       "6       TAT  8.166382e+05\n",
       "7       CDP  3.858125e+04\n",
       "8        CO  3.813210e+00\n",
       "9       NOX  1.071006e+02"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = gas.drop('TEY',axis=1)\n",
    "calc_vif(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "623b21ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_func(i):\n",
    "     x = (i-i.min())/(i.max()-i.min())\n",
    "     return (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe79ee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting The Data\n",
    "predictors = gas.drop('TEY',axis=1)\n",
    "target = gas['TEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19443c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15039"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e22188b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15039"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45416ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15039, 10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of train data\n",
    "predictors.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd48c8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15039,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6af862ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.184182</td>\n",
       "      <td>0.456050</td>\n",
       "      <td>0.951314</td>\n",
       "      <td>0.255758</td>\n",
       "      <td>0.091426</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.984015</td>\n",
       "      <td>0.135340</td>\n",
       "      <td>0.071522</td>\n",
       "      <td>0.596548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.182020</td>\n",
       "      <td>0.466391</td>\n",
       "      <td>0.955881</td>\n",
       "      <td>0.255721</td>\n",
       "      <td>0.094755</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.984015</td>\n",
       "      <td>0.133988</td>\n",
       "      <td>0.073372</td>\n",
       "      <td>0.597134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.185295</td>\n",
       "      <td>0.474664</td>\n",
       "      <td>0.939003</td>\n",
       "      <td>0.252571</td>\n",
       "      <td>0.097367</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.980608</td>\n",
       "      <td>0.134567</td>\n",
       "      <td>0.072576</td>\n",
       "      <td>0.593791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.189922</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.929126</td>\n",
       "      <td>0.252227</td>\n",
       "      <td>0.098033</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.983753</td>\n",
       "      <td>0.135533</td>\n",
       "      <td>0.072375</td>\n",
       "      <td>0.595984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.199830</td>\n",
       "      <td>0.493278</td>\n",
       "      <td>0.927708</td>\n",
       "      <td>0.255323</td>\n",
       "      <td>0.096650</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.983491</td>\n",
       "      <td>0.136692</td>\n",
       "      <td>0.073647</td>\n",
       "      <td>0.592087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>0.247272</td>\n",
       "      <td>0.408480</td>\n",
       "      <td>0.975092</td>\n",
       "      <td>0.263380</td>\n",
       "      <td>0.065868</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.884696</td>\n",
       "      <td>0.095739</td>\n",
       "      <td>0.102448</td>\n",
       "      <td>0.562214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>0.214075</td>\n",
       "      <td>0.414685</td>\n",
       "      <td>0.984153</td>\n",
       "      <td>0.256826</td>\n",
       "      <td>0.078672</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.806342</td>\n",
       "      <td>0.102113</td>\n",
       "      <td>0.109894</td>\n",
       "      <td>0.566100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>0.195962</td>\n",
       "      <td>0.422958</td>\n",
       "      <td>0.989922</td>\n",
       "      <td>0.251593</td>\n",
       "      <td>0.084614</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.651730</td>\n",
       "      <td>0.111772</td>\n",
       "      <td>0.180552</td>\n",
       "      <td>0.685449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>0.188443</td>\n",
       "      <td>0.433299</td>\n",
       "      <td>0.982936</td>\n",
       "      <td>0.246451</td>\n",
       "      <td>0.076777</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.754455</td>\n",
       "      <td>0.121431</td>\n",
       "      <td>0.141693</td>\n",
       "      <td>0.710578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>0.186173</td>\n",
       "      <td>0.441572</td>\n",
       "      <td>0.961821</td>\n",
       "      <td>0.242631</td>\n",
       "      <td>0.073141</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.875262</td>\n",
       "      <td>0.131090</td>\n",
       "      <td>0.112946</td>\n",
       "      <td>0.702665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             AT        AP        AH      AFDP      GTEP    TIT       TAT  \\\n",
       "0      0.184182  0.456050  0.951314  0.255758  0.091426  0.584  0.984015   \n",
       "1      0.182020  0.466391  0.955881  0.255721  0.094755  0.585  0.984015   \n",
       "2      0.185295  0.474664  0.939003  0.252571  0.097367  0.586  0.980608   \n",
       "3      0.189922  0.482937  0.929126  0.252227  0.098033  0.588  0.983753   \n",
       "4      0.199830  0.493278  0.927708  0.255323  0.096650  0.589  0.983491   \n",
       "...         ...       ...       ...       ...       ...    ...       ...   \n",
       "15034  0.247272  0.408480  0.975092  0.263380  0.065868  0.489  0.884696   \n",
       "15035  0.214075  0.414685  0.984153  0.256826  0.078672  0.455  0.806342   \n",
       "15036  0.195962  0.422958  0.989922  0.251593  0.084614  0.369  0.651730   \n",
       "15037  0.188443  0.433299  0.982936  0.246451  0.076777  0.424  0.754455   \n",
       "15038  0.186173  0.441572  0.961821  0.242631  0.073141  0.491  0.875262   \n",
       "\n",
       "            CDP        CO       NOX  \n",
       "0      0.135340  0.071522  0.596548  \n",
       "1      0.133988  0.073372  0.597134  \n",
       "2      0.134567  0.072576  0.593791  \n",
       "3      0.135533  0.072375  0.595984  \n",
       "4      0.136692  0.073647  0.592087  \n",
       "...         ...       ...       ...  \n",
       "15034  0.095739  0.102448  0.562214  \n",
       "15035  0.102113  0.109894  0.566100  \n",
       "15036  0.111772  0.180552  0.685449  \n",
       "15037  0.121431  0.141693  0.710578  \n",
       "15038  0.131090  0.112946  0.702665  \n",
       "\n",
       "[15039 rows x 10 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding normalization to train data.\n",
    "predictors1 = norm_func(predictors)\n",
    "predictors1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06bcf84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using train_test_split splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test= train_test_split(predictors1,target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97efbdae",
   "metadata": {},
   "source": [
    "# building a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11da9f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(12, activation='relu', input_shape=(10,)),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='linear'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e78ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1db6846f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2027.2211 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1801 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1814 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1780 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1798 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1780 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1791 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1814 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1797 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1804 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1785 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1791 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1777 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1792 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1797 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1791 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1788 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1792 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1787 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1783 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1808 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1780 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1787 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1798 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1785 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1794 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1774 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1798 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1783 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1794 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1798 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1791 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1787 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1781 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1785 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1797 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1804 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1801 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1783 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1808 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1783 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1781 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1777 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1802 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1791 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1805 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1777 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1797 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1792 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1791 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1783 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1798 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1798 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1787 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1801 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1774 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1798 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1781 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1792 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1809 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1797 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1797 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1801 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1792 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1798 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1785 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1804 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1805 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1785 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1798 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1791 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1788 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1797 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1781 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1785 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1785 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1791 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1808 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1787 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1774 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1788 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1794 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1802 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1792 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1808 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1791 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1792 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1791 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1792 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1801 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1787 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1804 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1791 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1818 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1788 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1792 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1787 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1794 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1805 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: -2031.1798 - accuracy: 0.0000e+00 - val_loss: -2030.6569 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(np.array(x_train),np.array(y_train),\n",
    "          batch_size=12, epochs=100,\n",
    "          validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83d9fd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 2ms/step - loss: -2030.6576 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284d3f89",
   "metadata": {},
   "source": [
    "# building another new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aebd5ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(10,)),\n",
    "    Dense(12, activation='relu'),\n",
    "    Dense(1, activation='linear'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "76786119",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "95fa5d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 4729.9121 - mse: 4729.9121 - val_loss: 46.7342 - val_mse: 46.7342\n",
      "Epoch 2/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 37.5256 - mse: 37.5256 - val_loss: 31.7782 - val_mse: 31.7782\n",
      "Epoch 3/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 28.5097 - mse: 28.5097 - val_loss: 26.9991 - val_mse: 26.9991\n",
      "Epoch 4/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 25.4073 - mse: 25.4073 - val_loss: 24.0384 - val_mse: 24.0384\n",
      "Epoch 5/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 23.0277 - mse: 23.0277 - val_loss: 21.3191 - val_mse: 21.3191\n",
      "Epoch 6/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 20.4307 - mse: 20.4307 - val_loss: 18.3119 - val_mse: 18.3119\n",
      "Epoch 7/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 17.1259 - mse: 17.1259 - val_loss: 15.0948 - val_mse: 15.0948\n",
      "Epoch 8/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 12.2948 - mse: 12.2948 - val_loss: 9.1861 - val_mse: 9.1861\n",
      "Epoch 9/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 7.5214 - mse: 7.5214 - val_loss: 6.0816 - val_mse: 6.0816\n",
      "Epoch 10/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 4.7855 - mse: 4.7855 - val_loss: 3.8141 - val_mse: 3.8141\n",
      "Epoch 11/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 3.4428 - mse: 3.4428 - val_loss: 3.2988 - val_mse: 3.2988\n",
      "Epoch 12/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 2.8697 - mse: 2.8697 - val_loss: 3.1645 - val_mse: 3.1645\n",
      "Epoch 13/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 2.5390 - mse: 2.5390 - val_loss: 2.2284 - val_mse: 2.2284\n",
      "Epoch 14/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 2.2271 - mse: 2.2271 - val_loss: 1.9658 - val_mse: 1.9658\n",
      "Epoch 15/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 1.9406 - mse: 1.9406 - val_loss: 2.3204 - val_mse: 2.3204\n",
      "Epoch 16/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 1.7371 - mse: 1.7371 - val_loss: 1.6113 - val_mse: 1.6113\n",
      "Epoch 17/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 1.5615 - mse: 1.5615 - val_loss: 1.3736 - val_mse: 1.3736\n",
      "Epoch 18/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 1.4037 - mse: 1.4037 - val_loss: 1.2914 - val_mse: 1.2914\n",
      "Epoch 19/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 1.2576 - mse: 1.2576 - val_loss: 1.1291 - val_mse: 1.1291\n",
      "Epoch 20/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 1.1419 - mse: 1.1419 - val_loss: 1.0361 - val_mse: 1.0361\n",
      "Epoch 21/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 1.0581 - mse: 1.0581 - val_loss: 0.9669 - val_mse: 0.9669\n",
      "Epoch 22/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.9808 - mse: 0.9808 - val_loss: 0.9092 - val_mse: 0.9092\n",
      "Epoch 23/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.9295 - mse: 0.9295 - val_loss: 0.8586 - val_mse: 0.8586\n",
      "Epoch 24/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.8582 - mse: 0.8582 - val_loss: 0.8258 - val_mse: 0.8258\n",
      "Epoch 25/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.8341 - mse: 0.8341 - val_loss: 0.8960 - val_mse: 0.8960\n",
      "Epoch 26/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.8009 - mse: 0.8009 - val_loss: 0.7434 - val_mse: 0.7434\n",
      "Epoch 27/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.7882 - mse: 0.7882 - val_loss: 0.7995 - val_mse: 0.7995\n",
      "Epoch 28/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.7485 - mse: 0.7485 - val_loss: 0.7314 - val_mse: 0.7314\n",
      "Epoch 29/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.7543 - mse: 0.7543 - val_loss: 0.6788 - val_mse: 0.6788\n",
      "Epoch 30/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.7300 - mse: 0.7300 - val_loss: 0.8675 - val_mse: 0.8675\n",
      "Epoch 31/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.7188 - mse: 0.7188 - val_loss: 1.0773 - val_mse: 1.0773\n",
      "Epoch 32/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.6882 - mse: 0.6882 - val_loss: 0.6611 - val_mse: 0.6611\n",
      "Epoch 33/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.6874 - mse: 0.6874 - val_loss: 0.7723 - val_mse: 0.7723\n",
      "Epoch 34/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.6901 - mse: 0.6901 - val_loss: 0.6601 - val_mse: 0.6601\n",
      "Epoch 35/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.6714 - mse: 0.6714 - val_loss: 0.6211 - val_mse: 0.6211\n",
      "Epoch 36/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.6634 - mse: 0.6634 - val_loss: 0.6132 - val_mse: 0.6132\n",
      "Epoch 37/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.6596 - mse: 0.6596 - val_loss: 0.5913 - val_mse: 0.5913\n",
      "Epoch 38/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.6481 - mse: 0.6481 - val_loss: 0.5713 - val_mse: 0.5713\n",
      "Epoch 39/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.6829 - mse: 0.6829 - val_loss: 0.5799 - val_mse: 0.5799\n",
      "Epoch 40/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.6441 - mse: 0.6441 - val_loss: 0.5681 - val_mse: 0.5681\n",
      "Epoch 41/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.6547 - mse: 0.6547 - val_loss: 0.5595 - val_mse: 0.5595\n",
      "Epoch 42/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.6322 - mse: 0.6322 - val_loss: 0.5900 - val_mse: 0.5900\n",
      "Epoch 43/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.6493 - mse: 0.6493 - val_loss: 0.6651 - val_mse: 0.6651\n",
      "Epoch 44/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.6350 - mse: 0.6350 - val_loss: 0.6873 - val_mse: 0.6873\n",
      "Epoch 45/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.6345 - mse: 0.6345 - val_loss: 0.5508 - val_mse: 0.5508\n",
      "Epoch 46/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.6210 - mse: 0.6210 - val_loss: 0.5511 - val_mse: 0.5511\n",
      "Epoch 47/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.6264 - mse: 0.6264 - val_loss: 0.5739 - val_mse: 0.5739\n",
      "Epoch 48/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.6193 - mse: 0.6193 - val_loss: 0.5633 - val_mse: 0.5633\n",
      "Epoch 49/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.6134 - mse: 0.6134 - val_loss: 0.5392 - val_mse: 0.5392\n",
      "Epoch 50/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.6252 - mse: 0.6252 - val_loss: 0.5356 - val_mse: 0.5356\n",
      "Epoch 51/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.6032 - mse: 0.6032 - val_loss: 0.6091 - val_mse: 0.6091\n",
      "Epoch 52/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.6115 - mse: 0.6115 - val_loss: 0.5377 - val_mse: 0.5377A: 0s - loss: 0.59 - ETA: 0s - loss: 0.6164 - mse: 0.6\n",
      "Epoch 53/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.6098 - mse: 0.6098 - val_loss: 0.5580 - val_mse: 0.5580\n",
      "Epoch 54/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.6234 - mse: 0.6234 - val_loss: 0.5277 - val_mse: 0.5277TA: 0s - loss: 0.6106 - mse: 0.\n",
      "Epoch 55/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.6086 - mse: 0.6086 - val_loss: 0.5710 - val_mse: 0.5710\n",
      "Epoch 56/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.5997 - mse: 0.5997 - val_loss: 0.5242 - val_mse: 0.5242\n",
      "Epoch 57/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.6015 - mse: 0.6015 - val_loss: 0.5213 - val_mse: 0.5213\n",
      "Epoch 58/100\n",
      "878/878 [==============================] - 2s 2ms/step - loss: 0.6033 - mse: 0.6033 - val_loss: 0.5192 - val_mse: 0.5192 0s - loss: 0.6400 - mse: 0.6 - ETA: 0s - loss: 0.6105 - ms - ETA: 0s - loss: 0.6066 - mse: 0.60\n",
      "Epoch 59/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5985 - mse: 0.5985 - val_loss: 0.7773 - val_mse: 0.7773\n",
      "Epoch 60/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5946 - mse: 0.5946 - val_loss: 0.5819 - val_mse: 0.5819\n",
      "Epoch 61/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.6032 - mse: 0.6032 - val_loss: 0.6906 - val_mse: 0.6906\n",
      "Epoch 62/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5973 - mse: 0.5973 - val_loss: 0.5566 - val_mse: 0.5566\n",
      "Epoch 63/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5925 - mse: 0.5925 - val_loss: 0.5118 - val_mse: 0.5118\n",
      "Epoch 64/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5907 - mse: 0.5907 - val_loss: 0.6457 - val_mse: 0.6457\n",
      "Epoch 65/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5920 - mse: 0.5920 - val_loss: 0.5174 - val_mse: 0.5174\n",
      "Epoch 66/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5963 - mse: 0.5963 - val_loss: 0.6124 - val_mse: 0.6124\n",
      "Epoch 67/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5942 - mse: 0.5942 - val_loss: 0.7283 - val_mse: 0.7283\n",
      "Epoch 68/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5887 - mse: 0.5887 - val_loss: 0.5560 - val_mse: 0.5560\n",
      "Epoch 69/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5752 - mse: 0.5752 - val_loss: 0.5648 - val_mse: 0.5648\n",
      "Epoch 70/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5902 - mse: 0.5902 - val_loss: 0.5623 - val_mse: 0.5623\n",
      "Epoch 71/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5829 - mse: 0.5829 - val_loss: 0.5055 - val_mse: 0.5055\n",
      "Epoch 72/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5855 - mse: 0.5855 - val_loss: 0.5074 - val_mse: 0.5074\n",
      "Epoch 73/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5816 - mse: 0.5816 - val_loss: 0.6572 - val_mse: 0.6572\n",
      "Epoch 74/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5703 - mse: 0.5703 - val_loss: 0.5033 - val_mse: 0.5033\n",
      "Epoch 75/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5791 - mse: 0.5791 - val_loss: 0.4964 - val_mse: 0.4964\n",
      "Epoch 76/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5752 - mse: 0.5752 - val_loss: 0.5369 - val_mse: 0.5369\n",
      "Epoch 77/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5747 - mse: 0.5747 - val_loss: 0.5180 - val_mse: 0.5180\n",
      "Epoch 78/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5751 - mse: 0.5751 - val_loss: 0.4990 - val_mse: 0.4990\n",
      "Epoch 79/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5750 - mse: 0.5750 - val_loss: 0.5554 - val_mse: 0.5554\n",
      "Epoch 80/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5711 - mse: 0.5711 - val_loss: 0.6663 - val_mse: 0.6663\n",
      "Epoch 81/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5764 - mse: 0.5764 - val_loss: 0.5268 - val_mse: 0.5268\n",
      "Epoch 82/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5655 - mse: 0.5655 - val_loss: 0.5020 - val_mse: 0.5020\n",
      "Epoch 83/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5771 - mse: 0.5771 - val_loss: 0.4875 - val_mse: 0.4875- loss: 0.5710 - mse\n",
      "Epoch 84/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5561 - mse: 0.5561 - val_loss: 0.4991 - val_mse: 0.4991\n",
      "Epoch 85/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5567 - mse: 0.5567 - val_loss: 0.6631 - val_mse: 0.6631\n",
      "Epoch 86/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5689 - mse: 0.5689 - val_loss: 0.4929 - val_mse: 0.4929\n",
      "Epoch 87/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5583 - mse: 0.5583 - val_loss: 0.5151 - val_mse: 0.5151\n",
      "Epoch 88/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5765 - mse: 0.5765 - val_loss: 0.4931 - val_mse: 0.4931\n",
      "Epoch 89/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5749 - mse: 0.5749 - val_loss: 0.4956 - val_mse: 0.4956\n",
      "Epoch 90/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5535 - mse: 0.5535 - val_loss: 0.4836 - val_mse: 0.4836\n",
      "Epoch 91/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5640 - mse: 0.5640 - val_loss: 0.6807 - val_mse: 0.6807\n",
      "Epoch 92/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5574 - mse: 0.5574 - val_loss: 0.5008 - val_mse: 0.5008\n",
      "Epoch 93/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5545 - mse: 0.5545 - val_loss: 0.9148 - val_mse: 0.91480s - loss: 0.5564 - mse: 0.5\n",
      "Epoch 94/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5587 - mse: 0.5587 - val_loss: 0.4934 - val_mse: 0.4934- loss: 0.5597 - mse: 0.559\n",
      "Epoch 95/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5489 - mse: 0.5489 - val_loss: 0.6164 - val_mse: 0.61640s - loss: 0.5521 \n",
      "Epoch 96/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5604 - mse: 0.5604 - val_loss: 0.4770 - val_mse: 0.4770\n",
      "Epoch 97/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5660 - mse: 0.5660 - val_loss: 0.4917 - val_mse: 0.4917\n",
      "Epoch 98/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5546 - mse: 0.5546 - val_loss: 0.5890 - val_mse: 0.5890\n",
      "Epoch 99/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5595 - mse: 0.5595 - val_loss: 0.4757 - val_mse: 0.4757\n",
      "Epoch 100/100\n",
      "878/878 [==============================] - 1s 2ms/step - loss: 0.5555 - mse: 0.5555 - val_loss: 0.4775 - val_mse: 0.4775\n"
     ]
    }
   ],
   "source": [
    "hist_1 = model1.fit(np.array(x_train),np.array(y_train),\n",
    "          batch_size=12, epochs=100,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce2e3aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4775 - mse: 0.4775\n",
      "mse: 47.75%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model1.evaluate(x_test, y_test)\n",
    "print(\"%s: %.2f%%\" % (model1.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bbf9a9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualize the train data\n",
    "# list all data in history\n",
    "model1.history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9011f032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist_1.history['mse'])\n",
    "plt.plot(hist_1.history['val_mse'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('mse')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f93ad940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(hist_1.history['loss'])\n",
    "plt.plot(hist_1.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e01dd6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383e8885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
